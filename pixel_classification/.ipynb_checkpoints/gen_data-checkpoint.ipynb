{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.ion()\n",
    "import os, cv2\n",
    "\n",
    "def read_pixels(folder, verbose = False):\n",
    "    '''\n",
    "    Reads 3-D pixel value of the top left corner of each image in folder\n",
    "    and returns an n x 3 matrix X containing the pixel values \n",
    "    '''  \n",
    "    n = len(next(os.walk(folder))[2]) # number of files\n",
    "    X = np.empty([n, 3])\n",
    "    i = 0\n",
    "\n",
    "    if verbose:\n",
    "        fig, ax = plt.subplots()\n",
    "        h = ax.imshow(np.random.randint(255, size=(28,28,3)).astype('uint8'))\n",
    "\n",
    "    for filename in os.listdir(folder):  \n",
    "        # read image\n",
    "        # img = plt.imread(os.path.join(folder,filename), 0)\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        # convert from BGR (opencv convention) to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # store pixel rgb value\n",
    "        X[i] = img[0,0].astype(np.float64)/255\n",
    "        i += 1\n",
    "\n",
    "        # display\n",
    "        if verbose:\n",
    "            h.set_data(img)\n",
    "            ax.set_title(filename)\n",
    "            fig.canvas.flush_events()\n",
    "            plt.show()\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3694,)\n",
      "(3694, 3)\n"
     ]
    }
   ],
   "source": [
    "folder = 'data/training'\n",
    "X1 = read_pixels(folder+'/red', verbose = False)\n",
    "X2 = read_pixels(folder+'/green')\n",
    "X3 = read_pixels(folder+'/blue')\n",
    "y1, y2, y3 = np.full(X1.shape[0],1), np.full(X2.shape[0], 2), np.full(X3.shape[0],3)\n",
    "X, y = np.concatenate((X1,X2,X3)), np.concatenate((y1,y2,y3))\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixel_classifier import PixelClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to train.....\n",
      "[1 1 1 ... 0 0 0]\n",
      "Loss for class 1 is: 0.637571564325683\n",
      "Loss for class 1 is: 0.6375713575710169\n",
      "Loss for class 1 is: 0.6375711508172098\n",
      "Loss for class 1 is: 0.6375709440642618\n",
      "Loss for class 1 is: 0.637570737312173\n",
      "Loss for class 1 is: 0.6375705305609433\n",
      "Loss for class 1 is: 0.6375703238105727\n",
      "Loss for class 1 is: 0.6375701170610607\n",
      "Loss for class 1 is: 0.6375699103124081\n",
      "Loss for class 1 is: 0.6375697035646142\n",
      "Loss for class 1 is: 0.6375694968176796\n",
      "Loss for class 1 is: 0.6375692900716038\n",
      "Loss for class 1 is: 0.637569083326387\n",
      "Loss for class 1 is: 0.6375688765820294\n",
      "Loss for class 1 is: 0.6375686698385307\n",
      "Loss for class 1 is: 0.6375684630958911\n",
      "Loss for class 1 is: 0.63756825635411\n",
      "Loss for class 1 is: 0.637568049613188\n",
      "Loss for class 1 is: 0.6375678428731252\n",
      "Loss for class 1 is: 0.6375676361339214\n",
      "Loss for class 1 is: 0.6375674293955762\n",
      "Loss for class 1 is: 0.6375672226580902\n",
      "Loss for class 1 is: 0.637567015921463\n",
      "Loss for class 1 is: 0.637566809185695\n",
      "Loss for class 1 is: 0.6375666024507857\n",
      "Loss for class 1 is: 0.6375663957167349\n",
      "Loss for class 1 is: 0.6375661889835432\n",
      "Loss for class 1 is: 0.637565982251211\n",
      "Loss for class 1 is: 0.6375657755197371\n",
      "Loss for class 1 is: 0.6375655687891225\n",
      "Loss for class 1 is: 0.6375653620593663\n",
      "Loss for class 1 is: 0.6375651553304694\n",
      "Loss for class 1 is: 0.6375649486024312\n",
      "Loss for class 1 is: 0.6375647418752517\n",
      "Loss for class 1 is: 0.6375645351489309\n",
      "Loss for class 1 is: 0.6375643284234693\n",
      "Loss for class 1 is: 0.6375641216988663\n",
      "Loss for class 1 is: 0.6375639149751222\n",
      "Loss for class 1 is: 0.6375637082522368\n",
      "Loss for class 1 is: 0.6375635015302107\n",
      "Loss for class 1 is: 0.6375632948090431\n",
      "Loss for class 1 is: 0.6375630880887341\n",
      "Loss for class 1 is: 0.6375628813692843\n",
      "Loss for class 1 is: 0.6375626746506928\n",
      "Loss for class 1 is: 0.6375624679329605\n",
      "Loss for class 1 is: 0.637562261216087\n",
      "Loss for class 1 is: 0.6375620545000715\n",
      "Loss for class 1 is: 0.6375618477849153\n",
      "Loss for class 1 is: 0.6375616410706179\n",
      "Loss for class 1 is: 0.6375614343571795\n",
      "Loss for class 1 is: 0.6375612276445992\n",
      "Loss for class 1 is: 0.6375610209328781\n",
      "Loss for class 1 is: 0.6375608142220155\n",
      "Loss for class 1 is: 0.6375606075120118\n",
      "Loss for class 1 is: 0.6375604008028666\n",
      "Loss for class 1 is: 0.6375601940945801\n",
      "Loss for class 1 is: 0.6375599873871526\n",
      "Loss for class 1 is: 0.6375597806805834\n",
      "Loss for class 1 is: 0.6375595739748732\n",
      "Loss for class 1 is: 0.6375593672700215\n",
      "Loss for class 1 is: 0.6375591605660285\n",
      "Loss for class 1 is: 0.6375589538628944\n",
      "Loss for class 1 is: 0.6375587471606184\n",
      "Loss for class 1 is: 0.6375585404592015\n",
      "Loss for class 1 is: 0.6375583337586431\n",
      "Loss for class 1 is: 0.6375581270589433\n",
      "Loss for class 1 is: 0.6375579203601024\n",
      "Loss for class 1 is: 0.6375577136621196\n",
      "Loss for class 1 is: 0.6375575069649958\n",
      "Loss for class 1 is: 0.6375573002687307\n",
      "Loss for class 1 is: 0.637557093573324\n",
      "Loss for class 1 is: 0.6375568868787757\n",
      "Loss for class 1 is: 0.6375566801850864\n",
      "Loss for class 1 is: 0.6375564734922553\n",
      "Loss for class 1 is: 0.6375562668002831\n",
      "Loss for class 1 is: 0.6375560601091692\n",
      "Loss for class 1 is: 0.637555853418914\n",
      "Loss for class 1 is: 0.6375556467295175\n",
      "Loss for class 1 is: 0.6375554400409792\n",
      "Loss for class 1 is: 0.6375552333532998\n",
      "Loss for class 1 is: 0.6375550266664785\n",
      "Loss for class 1 is: 0.6375548199805162\n",
      "Loss for class 1 is: 0.6375546132954123\n",
      "Loss for class 1 is: 0.6375544066111667\n",
      "Loss for class 1 is: 0.6375541999277796\n",
      "Loss for class 1 is: 0.6375539932452511\n",
      "Loss for class 1 is: 0.6375537865635812\n",
      "Loss for class 1 is: 0.6375535798827695\n",
      "Loss for class 1 is: 0.6375533732028165\n",
      "Loss for class 1 is: 0.6375531665237221\n",
      "Loss for class 1 is: 0.6375529598454859\n",
      "Loss for class 1 is: 0.637552753168108\n",
      "Loss for class 1 is: 0.6375525464915889\n",
      "Loss for class 1 is: 0.6375523398159283\n",
      "Loss for class 1 is: 0.6375521331411258\n",
      "Loss for class 1 is: 0.6375519264671821\n",
      "Loss for class 1 is: 0.6375517197940965\n",
      "Loss for class 1 is: 0.6375515131218695\n",
      "Loss for class 1 is: 0.6375513064505006\n",
      "Loss for class 1 is: 0.6375510997799906\n",
      "Trianing done....\n",
      "[0 0 0 ... 0 0 0]\n",
      "Loss for class 2 is: 0.8500651253413817\n",
      "Loss for class 2 is: 0.8500634799774837\n",
      "Loss for class 2 is: 0.850061834624937\n",
      "Loss for class 2 is: 0.8500601892837413\n",
      "Loss for class 2 is: 0.8500585439538956\n",
      "Loss for class 2 is: 0.8500568986354003\n",
      "Loss for class 2 is: 0.8500552533282555\n",
      "Loss for class 2 is: 0.8500536080324614\n",
      "Loss for class 2 is: 0.8500519627480172\n",
      "Loss for class 2 is: 0.8500503174749235\n",
      "Loss for class 2 is: 0.8500486722131806\n",
      "Loss for class 2 is: 0.8500470269627871\n",
      "Loss for class 2 is: 0.8500453817237432\n",
      "Loss for class 2 is: 0.8500437364960499\n",
      "Loss for class 2 is: 0.8500420912797068\n",
      "Loss for class 2 is: 0.8500404460747131\n",
      "Loss for class 2 is: 0.8500388008810692\n",
      "Loss for class 2 is: 0.8500371556987748\n",
      "Loss for class 2 is: 0.8500355105278302\n",
      "Loss for class 2 is: 0.8500338653682353\n",
      "Loss for class 2 is: 0.8500322202199898\n",
      "Loss for class 2 is: 0.8500305750830929\n",
      "Loss for class 2 is: 0.8500289299575463\n",
      "Loss for class 2 is: 0.8500272848433486\n",
      "Loss for class 2 is: 0.8500256397404997\n",
      "Loss for class 2 is: 0.850023994649\n",
      "Loss for class 2 is: 0.85002234956885\n",
      "Loss for class 2 is: 0.8500207045000487\n",
      "Loss for class 2 is: 0.8500190594425958\n",
      "Loss for class 2 is: 0.8500174143964919\n",
      "Loss for class 2 is: 0.8500157693617366\n",
      "Loss for class 2 is: 0.8500141243383309\n",
      "Loss for class 2 is: 0.8500124793262729\n",
      "Loss for class 2 is: 0.8500108343255633\n",
      "Loss for class 2 is: 0.8500091893362028\n",
      "Loss for class 2 is: 0.8500075443581908\n",
      "Loss for class 2 is: 0.8500058993915265\n",
      "Loss for class 2 is: 0.8500042544362111\n",
      "Loss for class 2 is: 0.8500026094922428\n",
      "Loss for class 2 is: 0.8500009645596236\n",
      "Loss for class 2 is: 0.8499993196383518\n",
      "Loss for class 2 is: 0.849997674728428\n",
      "Loss for class 2 is: 0.8499960298298523\n",
      "Loss for class 2 is: 0.8499943849426247\n",
      "Loss for class 2 is: 0.8499927400667443\n",
      "Loss for class 2 is: 0.8499910952022125\n",
      "Loss for class 2 is: 0.8499894503490271\n",
      "Loss for class 2 is: 0.8499878055071898\n",
      "Loss for class 2 is: 0.8499861606766997\n",
      "Loss for class 2 is: 0.8499845158575574\n",
      "Loss for class 2 is: 0.8499828710497619\n",
      "Loss for class 2 is: 0.8499812262533141\n",
      "Loss for class 2 is: 0.8499795814682135\n",
      "Loss for class 2 is: 0.8499779366944598\n",
      "Loss for class 2 is: 0.8499762919320534\n",
      "Loss for class 2 is: 0.8499746471809935\n",
      "Loss for class 2 is: 0.8499730024412806\n",
      "Loss for class 2 is: 0.8499713577129147\n",
      "Loss for class 2 is: 0.8499697129958951\n",
      "Loss for class 2 is: 0.8499680682902221\n",
      "Loss for class 2 is: 0.8499664235958965\n",
      "Loss for class 2 is: 0.8499647789129177\n",
      "Loss for class 2 is: 0.8499631342412842\n",
      "Loss for class 2 is: 0.8499614895809977\n",
      "Loss for class 2 is: 0.8499598449320575\n",
      "Loss for class 2 is: 0.8499582002944633\n",
      "Loss for class 2 is: 0.8499565556682152\n",
      "Loss for class 2 is: 0.8499549110533131\n",
      "Loss for class 2 is: 0.8499532664497573\n",
      "Loss for class 2 is: 0.8499516218575475\n",
      "Loss for class 2 is: 0.8499499772766835\n",
      "Loss for class 2 is: 0.8499483327071655\n",
      "Loss for class 2 is: 0.8499466881489928\n",
      "Loss for class 2 is: 0.8499450436021665\n",
      "Loss for class 2 is: 0.849943399066685\n",
      "Loss for class 2 is: 0.8499417545425496\n",
      "Loss for class 2 is: 0.8499401100297593\n",
      "Loss for class 2 is: 0.8499384655283144\n",
      "Loss for class 2 is: 0.8499368210382149\n",
      "Loss for class 2 is: 0.8499351765594607\n",
      "Loss for class 2 is: 0.8499335320920516\n",
      "Loss for class 2 is: 0.8499318876359874\n",
      "Loss for class 2 is: 0.8499302431912685\n",
      "Loss for class 2 is: 0.8499285987578943\n",
      "Loss for class 2 is: 0.8499269543358653\n",
      "Loss for class 2 is: 0.8499253099251808\n",
      "Loss for class 2 is: 0.8499236655258411\n",
      "Loss for class 2 is: 0.8499220211378465\n",
      "Loss for class 2 is: 0.8499203767611961\n",
      "Loss for class 2 is: 0.8499187323958901\n",
      "Loss for class 2 is: 0.8499170880419287\n",
      "Loss for class 2 is: 0.8499154436993115\n",
      "Loss for class 2 is: 0.8499137993680391\n",
      "Loss for class 2 is: 0.8499121550481106\n",
      "Loss for class 2 is: 0.8499105107395266\n",
      "Loss for class 2 is: 0.849908866442286\n",
      "Loss for class 2 is: 0.8499072221563899\n",
      "Loss for class 2 is: 0.8499055778818376\n",
      "Loss for class 2 is: 0.8499039336186295\n",
      "Loss for class 2 is: 0.8499022893667645\n",
      "Trianing done....\n",
      "[0 0 0 ... 1 1 1]\n",
      "Loss for class 3 is: 0.5620362161986847\n",
      "Loss for class 3 is: 0.5620361227846646\n",
      "Loss for class 3 is: 0.562036029370733\n",
      "Loss for class 3 is: 0.5620359359568898\n",
      "Loss for class 3 is: 0.5620358425431344\n",
      "Loss for class 3 is: 0.5620357491294679\n",
      "Loss for class 3 is: 0.5620356557158893\n",
      "Loss for class 3 is: 0.5620355623023989\n",
      "Loss for class 3 is: 0.562035468888997\n",
      "Loss for class 3 is: 0.5620353754756834\n",
      "Loss for class 3 is: 0.5620352820624579\n",
      "Loss for class 3 is: 0.5620351886493208\n",
      "Loss for class 3 is: 0.5620350952362718\n",
      "Loss for class 3 is: 0.5620350018233115\n",
      "Loss for class 3 is: 0.5620349084104391\n",
      "Loss for class 3 is: 0.562034814997655\n",
      "Loss for class 3 is: 0.5620347215849593\n",
      "Loss for class 3 is: 0.5620346281723518\n",
      "Loss for class 3 is: 0.5620345347598327\n",
      "Loss for class 3 is: 0.5620344413474018\n",
      "Loss for class 3 is: 0.5620343479350589\n",
      "Loss for class 3 is: 0.5620342545228049\n",
      "Loss for class 3 is: 0.5620341611106386\n",
      "Loss for class 3 is: 0.5620340676985609\n",
      "Loss for class 3 is: 0.5620339742865713\n",
      "Loss for class 3 is: 0.56203388087467\n",
      "Loss for class 3 is: 0.5620337874628569\n",
      "Loss for class 3 is: 0.5620336940511323\n",
      "Loss for class 3 is: 0.5620336006394958\n",
      "Loss for class 3 is: 0.5620335072279479\n",
      "Loss for class 3 is: 0.5620334138164877\n",
      "Loss for class 3 is: 0.5620333204051161\n",
      "Loss for class 3 is: 0.5620332269938328\n",
      "Loss for class 3 is: 0.5620331335826378\n",
      "Loss for class 3 is: 0.5620330401715309\n",
      "Loss for class 3 is: 0.5620329467605123\n",
      "Loss for class 3 is: 0.5620328533495821\n",
      "Loss for class 3 is: 0.56203275993874\n",
      "Loss for class 3 is: 0.5620326665279863\n",
      "Loss for class 3 is: 0.5620325731173209\n",
      "Loss for class 3 is: 0.562032479706744\n",
      "Loss for class 3 is: 0.5620323862962548\n",
      "Loss for class 3 is: 0.5620322928858541\n",
      "Loss for class 3 is: 0.5620321994755417\n",
      "Loss for class 3 is: 0.5620321060653176\n",
      "Loss for class 3 is: 0.5620320126551818\n",
      "Loss for class 3 is: 0.5620319192451342\n",
      "Loss for class 3 is: 0.5620318258351749\n",
      "Loss for class 3 is: 0.5620317324253039\n",
      "Loss for class 3 is: 0.562031639015521\n",
      "Loss for class 3 is: 0.5620315456058267\n",
      "Loss for class 3 is: 0.5620314521962204\n",
      "Loss for class 3 is: 0.5620313587867023\n",
      "Loss for class 3 is: 0.5620312653772725\n",
      "Loss for class 3 is: 0.5620311719679312\n",
      "Loss for class 3 is: 0.5620310785586778\n",
      "Loss for class 3 is: 0.5620309851495129\n",
      "Loss for class 3 is: 0.5620308917404363\n",
      "Loss for class 3 is: 0.5620307983314481\n",
      "Loss for class 3 is: 0.5620307049225478\n",
      "Loss for class 3 is: 0.562030611513736\n",
      "Loss for class 3 is: 0.5620305181050125\n",
      "Loss for class 3 is: 0.562030424696377\n",
      "Loss for class 3 is: 0.5620303312878299\n",
      "Loss for class 3 is: 0.5620302378793709\n",
      "Loss for class 3 is: 0.5620301444710005\n",
      "Loss for class 3 is: 0.5620300510627182\n",
      "Loss for class 3 is: 0.5620299576545242\n",
      "Loss for class 3 is: 0.5620298642464183\n",
      "Loss for class 3 is: 0.5620297708384008\n",
      "Loss for class 3 is: 0.5620296774304716\n",
      "Loss for class 3 is: 0.5620295840226306\n",
      "Loss for class 3 is: 0.5620294906148777\n",
      "Loss for class 3 is: 0.5620293972072133\n",
      "Loss for class 3 is: 0.5620293037996371\n",
      "Loss for class 3 is: 0.5620292103921489\n",
      "Loss for class 3 is: 0.5620291169847493\n",
      "Loss for class 3 is: 0.5620290235774378\n",
      "Loss for class 3 is: 0.5620289301702146\n",
      "Loss for class 3 is: 0.5620288367630795\n",
      "Loss for class 3 is: 0.5620287433560329\n",
      "Loss for class 3 is: 0.5620286499490744\n",
      "Loss for class 3 is: 0.5620285565422043\n",
      "Loss for class 3 is: 0.5620284631354222\n",
      "Loss for class 3 is: 0.5620283697287286\n",
      "Loss for class 3 is: 0.5620282763221232\n",
      "Loss for class 3 is: 0.5620281829156057\n",
      "Loss for class 3 is: 0.562028089509177\n",
      "Loss for class 3 is: 0.5620279961028364\n",
      "Loss for class 3 is: 0.562027902696584\n",
      "Loss for class 3 is: 0.5620278092904196\n",
      "Loss for class 3 is: 0.5620277158843437\n",
      "Loss for class 3 is: 0.562027622478356\n",
      "Loss for class 3 is: 0.5620275290724566\n",
      "Loss for class 3 is: 0.5620274356666455\n",
      "Loss for class 3 is: 0.5620273422609224\n",
      "Loss for class 3 is: 0.5620272488552879\n",
      "Loss for class 3 is: 0.5620271554497415\n",
      "Loss for class 3 is: 0.5620270620442831\n",
      "Loss for class 3 is: 0.5620269686389133\n",
      "Trianing done....\n"
     ]
    }
   ],
   "source": [
    "myPixelClassifier = PixelClassifier()\n",
    "weigths = myPixelClassifier.train(X, y, 100, X.shape[0], lr=0.001, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.75591492,  0.18920204, -0.81089434, -0.8607184 ]), 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weigths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "folder = 'data/validation/red'\n",
    "  \n",
    "X = read_pixels(folder)\n",
    "myPixelClassifier = PixelClassifier()\n",
    "y = myPixelClassifier.classify(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.000000\n"
     ]
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "print('Precision: %f' % (sum(y==1)/y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # features = X.shape[1]\n",
    "    # self.weights = np.random.randn(features, 1) / features\n",
    "    # self.bias = 0\n",
    "    # print(self.weights.shape)\n",
    "    # for i in range(epochs):\n",
    "    #   #print(X_batch.shape)\n",
    "    #   for X_b, y_b in self.get_minibatch(X, y, batchsize):\n",
    "    #     y_pred = self.sigmoid(X_b, self.weights, self.bias)\n",
    "    #     dw, db = self.calc_gradient(X_b, y_b, y_pred)\n",
    "\n",
    "    #     self.weights = self.weights - lr*dw\n",
    "    #     self.bias = self.bias - lr*db\n",
    "\n",
    "    #   y_epoch = self.sigmoid(X, self.weights, self.bias)\n",
    "    #   loss_epoch = self.calc_loss(y, y_epoch)\n",
    "    #   print(\"Loss after epoch {} is {}\".format(i, loss_epoch))\n",
    "    \n",
    "    # return self.weights, self.bias"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f846f0a7e859806ccd3dacc393940d320b9b595981e467079bbc199c329d70da"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
